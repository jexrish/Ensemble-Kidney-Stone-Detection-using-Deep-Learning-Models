# -*- coding: utf-8 -*-
"""proj.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HmJZiGdJ5q7q8GhKj07vWR69S0glJMkn
"""

# Install TensorFlow if it's not already available in the environment
pip install tensorflow

# ==============================================================================
# All Library Imports
# ==============================================================================

# Standard Library
import os
import random

# Third-Party Libraries
import cv2
import joblib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from PIL import Image
from sklearn.decomposition import PCA
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import (accuracy_score, auc, classification_report,
                             confusion_matrix, ConfusionMatrixDisplay, roc_curve)
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.svm import SVC
from tqdm import tqdm

# TensorFlow / Keras / Google Colab
from google.colab import drive
from tensorflow.keras.applications import InceptionV3, MobileNetV2, ResNet101
from tensorflow.keras.applications.densenet import \
    preprocess_input as densenet_preprocess
from tensorflow.keras.applications.inception_v3 import \
    preprocess_input as inception_preprocess
from tensorflow.keras.applications.resnet import \
    preprocess_input as resnet_preprocess
from tensorflow.keras.layers import GlobalAveragePooling2D
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator


# ==============================================================================
# Main Code Body
# ==============================================================================

# --- 1. SETUP AND DATA LOADING ---

# Mount Google Drive to access the dataset files
drive.mount('/content/drive')

# Define the path to the main dataset directory
dataset_path = '/content/drive/MyDrive/KidneyCTDataset'
dataset_dir = "/content/drive/MyDrive/KidneyCTDataset"
# Define the class names which correspond to the folder names
categories = ["healthy", "kidney_stone"]

# --- 2. IMAGE PREPROCESSING AND AUGMENTATION ---

def preprocess_image(image_path):
    """Loads an image, resizes it to 224x224, and converts it from BGR to RGB."""
    image = cv2.imread(image_path)
    if image is None:
        return None
    image = cv2.resize(image, (224, 224))
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    return image

# Configure the settings for data augmentation to artificially expand the dataset
datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

def augment_image(image_path, num_augments=3, target_size=(224, 224)):
    """Generates a specified number of augmented versions of a single image."""
    img = image.load_img(image_path, target_size=target_size)
    x = image.img_to_array(img)
    x = x.reshape((1,) + x.shape)
    augmented = []
    # Generate batches of augmented images
    for batch in datagen.flow(x, batch_size=1):
        augmented.append(batch[0])
        if len(augmented) == num_augments:
            break
    return augmented

# --- 3. DATA EXPLORATION AND VISUALIZATION ---

# Walk through the dataset directory to collect all image paths and their corresponding labels
image_paths = []
labels = []
for label, category in enumerate(categories):
    category_path = os.path.join(dataset_dir, category)
    if os.path.exists(category_path):
        for img_name in os.listdir(category_path):
            image_paths.append(os.path.join(category_path, img_name))
            labels.append(label) # 0 for healthy, 1 for kidney_stone

def get_images_by_label(label_val, count):
    """Helper function to retrieve a few sample images for a specific label."""
    images = [];
    for path, label in zip(image_paths, labels):
        if label == label_val:
            images.append(path)
        if len(images) == count:
            break
    return images

# Get 3 sample images from each class for visualization
label_0_images = get_images_by_label(0, 3)
label_1_images = get_images_by_label(1, 3)

# Combine the samples and their titles for plotting
images_to_show = label_0_images + label_1_images
titles = ['Label: 0 (Healthy)'] * 3 + ['Label: 1 (Stone)'] * 3

# Display the sample images
plt.figure(figsize=(12, 6))
for i, (img_path, title) in enumerate(zip(images_to_show, titles)):
    img = Image.open(img_path)
    plt.subplot(2, 3, i + 1)
    plt.imshow(img)
    plt.title(title)
    plt.axis('off')

plt.tight_layout()
plt.show()

# Check the distribution of classes to see if the dataset is balanced
label_counts = pd.Series(labels).value_counts()
print("Class Distribution:\n", label_counts)


# --- 4. FEATURE EXTRACTION USING PRE-TRAINED MODELS ---

# --- Part 4a: ResNet101 Feature Extraction ---

# Load the ResNet101 model, pre-trained on ImageNet, without the final classification layer
base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
# Freeze the layers of the base model so they are not updated during training
base_model.trainable = False
# Create a new model that outputs the global average pooled features from the base model
feature_extractor = Model(inputs=base_model.input, outputs=GlobalAveragePooling2D()(base_model.output))

def image_generator(image_paths, batch_size=32):
    """A generator to load, preprocess, and yield images in batches for ResNet101."""
    for i in range(0, len(image_paths), batch_size):
        batch_imgs = []
        batch_paths = image_paths[i:i + batch_size]
        for path in batch_paths:
            img = preprocess_image(path)
            if img is not None:
                # Use the specific preprocessing function for ResNet
                img = resnet_preprocess(img * 255.0)
                batch_imgs.append(img)
        yield np.array(batch_imgs)

# Process all images in batches to extract features using the ResNet101 model
features = []
for batch in tqdm(image_generator(image_paths), total=len(image_paths) // 32):
    feat = feature_extractor.predict(batch)
    features.append(feat)

# Combine the batch features into a single NumPy array
resnet_features = np.vstack(features)
print("ResNet101 features shape:", resnet_features.shape)


# --- Part 4b: InceptionV3 Feature Extraction ---

# Load the InceptionV3 model, also pre-trained on ImageNet, with global average pooling
base_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg')
# This model will serve as our feature extractor
feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)

def image_generator(image_paths, batch_size=32, target_size=(299, 299)):
    """A generator to load and preprocess images in batches for InceptionV3."""
    batch = []
    for path in image_paths:
        img = image.load_img(path, target_size=target_size)
        img_array = image.img_to_array(img)
        # Use the specific preprocessing function for InceptionV3
        img_array = inception_preprocess(img_array)
        batch.append(img_array)

        if len(batch) == batch_size:
            yield np.array(batch)
            batch = []

    if batch: # Yield the last, possibly smaller, batch
        yield np.array(batch)

# Get the list of image paths again (note: this is redundant but harmless)
image_dir = "/content/drive/MyDrive/KidneyCTDataset"
image_paths = []
for category in ['healthy', 'kidney_stone']:
    category_path = os.path.join(image_dir, category)
    for fname in os.listdir(category_path):
        if fname.endswith(('.jpg', '.png')):
            image_paths.append(os.path.join(category_path, fname))

print("Number of images found:", len(image_paths))

# A quick check to see the shape of a single batch
for batch in image_generator(image_paths):
    print("Sample batch shape for InceptionV3:", batch.shape)
    break

# Process all images to extract features using the InceptionV3 model
features = []
for batch in tqdm(image_generator(image_paths), total=len(image_paths) // 32 + 1):
    feat = feature_extractor.predict(batch)
    features.append(feat)

# Combine the batch features into a single NumPy array
inception_features = np.vstack(features)
print("InceptionV3 features shape:", inception_features.shape)


# --- Part 4c: Combine Features ---

# Concatenate the features from both models horizontally to create a hybrid feature set
combined_features = np.concatenate((resnet_features, inception_features), axis=1)
print("Combined feature shape:", combined_features.shape)


# --- 5. MODEL TRAINING PREPARATION ---

# Split the combined features and labels into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    combined_features, labels, test_size=0.2, random_state=42, stratify=labels
)
print(f"Training samples: {len(X_train)}, Testing samples: {len(X_test)}")

# Define feature matrix X and label vector y
X = combined_features
y = []
for path in image_paths:
    if 'healthy' in path:
        y.append(0)
    elif 'kidney_stone' in path:
        y.append(1)
y = np.array(y)

# Standardize the features (important for models like SVM)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the scaled data into training and testing sets for model training
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# Apply Principal Component Analysis (PCA) to reduce dimensionality and noise
pca = PCA(n_components=100)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)


# --- 6. MODEL TRAINING AND HYPERPARAMETER TUNING ---

# Create a machine learning pipeline that first scales the data, then applies a model
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', SVC())
])

# Define a grid of parameters to search for the best SVC model
param_grid = {
    'model__C': [0.1, 1, 10],
    'model__kernel': ['linear', 'rbf'],
    'model__gamma': ['scale', 'auto']
}

# Set up GridSearchCV to find the best parameters using 5-fold cross-validation
grid = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

# Train the GridSearchCV object
grid.fit(X_train, y_train)

# Make predictions on the test set with the best found model
y_pred = grid.predict(X_test)
print("Initial GridSearchCV Accuracy:", accuracy_score(y_test, y_pred))

# --- Part 6a: Fine-tuning SVM and KNN individually ---

# Create a pipeline for SVM
svm_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('svc', SVC())
])
# Define parameter grid specifically for SVM
svm_param_grid = {
    'svc__C': [0.1, 1, 10],
    'svc__kernel': ['linear', 'rbf'],
    'svc__gamma': ['scale', 'auto']
}
# Find the best SVM model
svm_grid = GridSearchCV(svm_pipeline, param_grid=svm_param_grid, cv=5, scoring='accuracy')
svm_grid.fit(X_train, y_train)
print("Best SVM params:", svm_grid.best_params_)
print("Best SVM cross-validation accuracy:", svm_grid.best_score_)

# Create a pipeline for KNN
knn_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('knn', KNeighborsClassifier())
])
# Define parameter grid specifically for KNN
knn_param_grid = {
    'knn__n_neighbors': [3, 5, 7],
    'knn__weights': ['uniform', 'distance'],
    'knn__metric': ['euclidean', 'manhattan']
}
# Find the best KNN model
knn_grid = GridSearchCV(knn_pipeline, param_grid=knn_param_grid, cv=5, scoring='accuracy')
knn_grid.fit(X_train, y_train)
print("Best KNN params:", knn_grid.best_params_)
print("Best KNN cross-validation accuracy:", knn_grid.best_score_)

# Check the training and testing accuracy of the first grid search model
train_acc = grid.score(X_train, y_train)
test_acc = grid.score(X_test, y_test)
print("GridSearchCV Train Accuracy:", train_acc)
print("GridSearchCV Test Accuracy:", test_acc)


# --- Part 6b: Training an Ensemble Model (Voting Classifier) ---

# Define the base models for the ensemble. SVC needs probability=True for soft voting.
svm = SVC(kernel='rbf', probability=True)
knn = KNeighborsClassifier()

# Create a soft voting classifier that combines the predictions of SVM and KNN
voting = VotingClassifier(estimators=[
    ('svm', svm),
    ('knn', knn)
], voting='soft')

# Define a parameter grid for the components of the voting classifier
param_grid = {
    'svm__C': [0.1, 1, 10],
    'knn__n_neighbors': [3, 5, 7]
}

# Use GridSearchCV to find the best parameters for the ensemble model
grid = GridSearchCV(estimator=voting, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid.fit(X_train, y_train)


# --- 7. MODEL EVALUATION AND VISUALIZATION ---

# Make predictions with the final trained ensemble model
y_pred = grid.predict(X_test)
# Get the probability scores for the positive class (for ROC curve)
y_prob = grid.predict_proba(X_test)[:, 1]

# Print detailed evaluation metrics
print("Final Model Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Visualize the Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=categories)
disp.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.show()

# Calculate and Visualize the ROC Curve and AUC Score
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--') # Dashed line for random guess
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.grid()
plt.show()


# --- 8. SAVE THE TRAINED MODEL ---

# Save the entire trained GridSearchCV object (which includes the best model) to a file
joblib.dump(grid, '/content/drive/MyDrive/kidney_hybrid_model.pkl')


# --- 9. PREDICTION FUNCTION FOR NEW IMAGES ---

def predict_image(image_path, resnet_model, inception_model, trained_model, categories):
    """
    Takes a single image path and returns a prediction using the full hybrid pipeline.
    
    Args:
        image_path (str): Path to the input image.
        resnet_model: The ResNet101 feature extractor model.
        inception_model: The InceptionV3 feature extractor model.
        trained_model: The final trained classifier (e.g., the Voting Classifier).
        categories (list): List of class names.

    Returns:
        str: The predicted class label.
    """
    # Preprocess for ResNet101
    img = cv2.imread(image_path)
    img_resnet = cv2.resize(img, (224, 224))
    img_resnet = cv2.cvtColor(img_resnet, cv2.COLOR_BGR2RGB)
    img_resnet = resnet_preprocess(img_resnet.astype(np.float32) * 255.0)
    img_resnet = np.expand_dims(img_resnet, axis=0)
    # Extract ResNet101 features
    resnet_feat = resnet_model.predict(img_resnet)

    # Preprocess for InceptionV3
    img_incep = image.load_img(image_path, target_size=(299, 299))
    img_incep = image.img_to_array(img_incep)
    img_incep = inception_preprocess(img_incep)
    img_incep = np.expand_dims(img_incep, axis=0)
    # Extract InceptionV3 features
    inception_feat = inception_model.predict(img_incep)

    # Combine features in the same way as during training
    combined_feat = np.concatenate((resnet_feat, inception_feat), axis=1)

    # Make a prediction using the final trained model
    pred = trained_model.predict(combined_feat)
    class_label = categories[int(pred[0])]

    return class_label

"""--------------------------------------------------------------------------------------------------------------------
The following block for re-running experiments or alternative approaches.
--------------------------------------------------------------------------------------------------------------------
"""
# This block re-defines and fits an SVM pipeline.
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('svc', SVC(probability=True))
])

param_grid = {
    'svc__C': [0.1, 1, 10],
    'svc__kernel': ['linear', 'rbf'],
    'svc__gamma': ['scale', 'auto']
}

grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')
grid.fit(X_train, y_train)

print("Best Cross-Val Accuracy (Re-run):", grid.best_score_)
y_pred = grid.predict(X_test)
print("Test Accuracy (Re-run):", accuracy_score(y_test, y_pred))

# This block demonstrates re-splitting the data.
X = combined_features
y = labels
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2) # Overwrites previous split

# This block trains individual SVM and KNN classifiers without a grid search.
# 1. Re-create labels
labels = []
for path in image_paths:
    if 'healthy' in path: labels.append(0)
    elif 'kidney_stone' in path: labels.append(1)
labels = np.array(labels)
# 2. Re-scale features
scaler = StandardScaler()
combined_features_scaled = scaler.fit_transform(combined_features)
# 3. Re-split data
X_train, X_test, y_train, y_test = train_test_split(
    combined_features_scaled, labels, test_size=0.2, random_state=42, stratify=labels
)
# 4. Train and evaluate SVM
svm_clf = SVC(kernel='rbf', probability=True)
svm_clf.fit(X_train, y_train)
svm_preds = svm_clf.predict(X_test)
print("Individual SVM Classification Report:\n", classification_report(y_test, svm_preds))
print("Individual SVM Accuracy:", accuracy_score(y_test, svm_preds))
# 5. Train and evaluate KNN
knn_clf = KNeighborsClassifier(n_neighbors=5)
knn_clf.fit(X_train, y_train)
knn_preds = knn_clf.predict(X_test)
print("Individual KNN Classification Report:\n", classification_report(y_test, knn_preds))
print("Individual KNN Accuracy:", accuracy_score(y_test, knn_preds))

# --- FINAL REFINED WORKFLOW ---
# This block represents a complete, refined workflow from data prep to saving predictions.

# 1. Prepare Labels
labels = []
for path in image_paths:
    if 'healthy' in path: labels.append(0)
    elif 'kidney_stone' in path: labels.append(1)
labels = np.array(labels)

# 2. Split Data (while keeping track of indices for filename mapping)
X = combined_features
y = labels
X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(
    X, y, list(range(len(X))), test_size=0.2, random_state=42, stratify=y)

# 3. Scale Features (fit on train, transform on both train and test to prevent data leakage)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. PCA with more components to retain more variance
pca = PCA(n_components=200)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# 5. Voting Classifier with a refined parameter grid and balanced class weights
svm = SVC(kernel='rbf', probability=True, class_weight='balanced')
knn = KNeighborsClassifier()
voting = VotingClassifier(estimators=[('svm', svm), ('knn', knn)], voting='soft')

param_grid = {
    'svm__C': [0.5, 1, 2],
    'knn__n_neighbors': [3, 5],
}
grid = GridSearchCV(estimator=voting, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid.fit(X_train_pca, y_train)

# 6. Evaluate the final model
y_pred = grid.predict(X_test_pca)
y_prob = grid.predict_proba(X_test_pca)[:, 1]

print("\n--- Final Refined Model Evaluation ---")
print("Best Parameters:", grid.best_params_)
print("Train Accuracy:", grid.score(X_train_pca, y_train))
print("Test Accuracy:", grid.score(X_test_pca, y_test))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# 7. Plot final ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (Final Model)')
plt.legend()
plt.grid()
plt.show()

# 8. Save test set predictions to a CSV file for analysis
test_filenames = [os.path.basename(image_paths[i]) for i in test_idx]
df = pd.DataFrame({
    'Filename': test_filenames,
    'True Label': y_test,
    'Predicted Label': y_pred,
    'Probability (Positive)': y_prob
})
df.to_csv('/content/drive/MyDrive/kidney_predictions.csv', index=False)
print("Predictions saved to /content/drive/MyDrive/kidney_predictions.csv")